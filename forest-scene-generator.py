# -*- coding: utf-8 -*-
"""textToImage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TbxrUhRvqIEbdalMlZZmi76Vcpptcr2A
"""

# Install required packages
!pip install -q gradio pyzbar opencv-python numpy diffusers transformers accelerate safetensors
!apt-get update && apt-get install -y libzbar0

import os
import random
import tempfile
import time
import numpy as np
import cv2
import torch
import gradio as gr


# Import diffusion model components after installation
from diffusers import DiffusionPipeline, AutoencoderKL
from huggingface_hub import login
from PIL import Image

# ------------------------------------------------
# Hugging Face Login - Replace with your token or use Colab secrets
# ------------------------------------------------
# Using a public token for demo purposes - replace with your own token!
# In a real setup, use Colab secrets management instead
HF_TOKEN = "Your Hugging Face Token"  # For demonstration only

# ------------------------------------------------
# Prompt Components for Forest Generation
# ------------------------------------------------
texture_terms = [
    "dense foliage", "rocky terrain", "fallen logs", "moss-covered ground",
    "leaf litter", "twisted roots", "uneven terrain", "detailed vegetation",
    "complex undergrowth", "varied tree bark", "misty atmosphere", "sunlight filtering through trees"
]

detail_terms = [
    "intricate details", "high texture contrast", "complex patterns",
    "sharp focus", "clear shadows", "detailed foreground", "natural lighting",
    "photorealistic quality", "deep depth of field"
]

style_terms = [
    "ultra-detailed photography", "cinematic composition", "professional nature photography",
    "National Geographic style", "wildlife photography", "8K resolution"
]

# ------------------------------------------------
# Model Management Functions
# ------------------------------------------------
generation_pipe = None
generation_device = "cuda" if torch.cuda.is_available() else "cpu"

def load_generation_models():
    """Load generation models on first use"""
    global generation_pipe

    if generation_pipe is None:
        try:
            # Login to Hugging Face
            login(HF_TOKEN)

            # Log status
            print(f"Loading models on {generation_device}...")
            start_time = time.time()

            # Set up the VAE for better memory efficiency
            vae = AutoencoderKL.from_pretrained(
                "madebyollin/sdxl-vae-fp16-fix",
                torch_dtype=torch.float16 if generation_device == "cuda" else torch.float32
            )

            # Load base model
            pipe = DiffusionPipeline.from_pretrained(
                "stabilityai/stable-diffusion-xl-base-1.0",
                vae=vae,
                torch_dtype=torch.float16 if generation_device == "cuda" else torch.float32,
                variant="fp16" if generation_device == "cuda" else None,
                use_safetensors=True,
            )

            # Move to appropriate device
            pipe.to(generation_device)

            # Load LoRA weights for forest specialization
            pipe.load_lora_weights("phoenix007654/forest_updated_LoRA")

            # Optional memory optimization for Colab
            if generation_device == "cuda":
                pipe.enable_attention_slicing()

            generation_pipe = pipe

            load_time = time.time() - start_time
            print(f"Models loaded successfully in {load_time:.2f} seconds")
            return f"Models loaded successfully on {generation_device} in {load_time:.2f} seconds"
        except Exception as e:
            error_msg = f"Failed to load models: {str(e)}"
            print(error_msg)
            return error_msg
    return f"Models already loaded on {generation_device}"

# ------------------------------------------------
# Image Generation Functions
# ------------------------------------------------
def generate_forest_prompt(base_prompt=None):
    """Generate optimized forest prompt for variance masking"""
    if base_prompt and base_prompt.strip():
        # User provided their own prompt - enhance it
        return f"{base_prompt}, forest scene, {random.choice(texture_terms)}, {random.choice(style_terms)}"
    else:
        # Generate default forest prompt
        texture = random.choice(texture_terms)
        detail = random.choice(detail_terms)
        style = random.choice(style_terms)
        return f"A forest scene with {texture} and {detail}, daytime, {style}"

def generate_image(prompt="", negative_prompt="", steps=40, guidance=7.5, seed=-1, progress=gr.Progress()):
    """Generate image based on parameters with progress tracking"""
    try:
        # Load models if needed
        if generation_pipe is None:
            load_status = load_generation_models()
            if "Failed" in load_status:
                return None, "", load_status, {}, {}

        # Process prompt
        forest_prompt = generate_forest_prompt(prompt) if prompt else generate_forest_prompt()

        # Process negative prompt
        if not negative_prompt:
            negative_prompt = "smooth, blurry, flat, low detail, cartoonish, painting, drawing, digital art, anime, manga"

        # Set random seed if not specified
        if seed < 0:
            seed = random.randint(0, 2147483647)
        generator = torch.Generator(device=generation_device).manual_seed(seed)

        # Parameter logging
        params = {
            "Prompt": forest_prompt,
            "Negative Prompt": negative_prompt,
            "Steps": steps,
            "Guidance Scale": guidance,
            "Seed": seed,
            "Device": generation_device
        }

        # Setup callback for progress tracking
        def callback(step, timestep, latents):
            progress((step + 1) / steps)
            return

        # Log start of generation
        start_time = time.time()
        progress(0)

        # Generate image
        output = generation_pipe(
            prompt=forest_prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=steps,
            guidance_scale=guidance,
            generator=generator,
            callback=callback,
            callback_steps=1
        )

        # Get the generated image
        image = output.images[0]

        # Calculate metrics
        gen_time = time.time() - start_time

        # Save generated image
        output_path = os.path.join(tempfile.gettempdir(), f"forest_gen_{seed}.png")
        image.save(output_path)

        # Create diffusion process metrics
        diffusion_info = {
            "Generation Time": f"{gen_time:.2f} seconds",
            "Steps Per Second": f"{steps/gen_time:.2f}",
            "Memory Used": f"{torch.cuda.max_memory_allocated()/1024**3:.2f} GB" if torch.cuda.is_available() else "N/A",
            "Pipeline": "Stable Diffusion XL + Forest LoRA"
        }

        progress(1.0)
        return output_path, forest_prompt, "Generation successful!", params, diffusion_info

    except Exception as e:
        error_msg = f"Generation failed: {str(e)}"
        print(error_msg)
        return None, "", error_msg, {}, {}

# ------------------------------------------------
# Gradio Interface Setup
# ------------------------------------------------
def create_gradio_interface():
    with gr.Blocks(title="Forest Scene Generator") as app:
        gr.Markdown("# ðŸŒ² AI Forest Scene Generator")
        gr.Markdown("Generate detailed forest scenes using Stable Diffusion XL with specialized Forest LoRA")

        with gr.Row():
            with gr.Column(scale=2):
                # Input controls
                prompt_input = gr.Textbox(
                    label="Prompt (Optional - leave empty for random forest generation)",
                    placeholder="Enter a custom prompt or leave empty for an auto-generated forest prompt",
                    lines=2
                )

                negative_prompt = gr.Textbox(
                    label="Negative Prompt",
                    placeholder="What you don't want to see in the image",
                    value="smooth, blurry, flat, low detail, cartoonish, painting, drawing",
                    lines=2
                )

                with gr.Row():
                    with gr.Column(scale=1):
                        steps_slider = gr.Slider(
                            minimum=20, maximum=100, value=40, step=5,
                            label="Diffusion Steps"
                        )

                    with gr.Column(scale=1):
                        guidance_slider = gr.Slider(
                            minimum=1.0, maximum=15.0, value=7.5, step=0.5,
                            label="Guidance Scale"
                        )

                seed_input = gr.Number(
                    label="Seed (-1 for random)",
                    value=-1,
                    precision=0
                )

                generate_btn = gr.Button("ðŸŒ² Generate Forest Scene", variant="primary")

            # Output display
            with gr.Column(scale=3):
                output_image = gr.Image(type="filepath", label="Generated Forest")
                generated_prompt = gr.Textbox(label="Generated Prompt", lines=2)
                status_output = gr.Textbox(label="Status")

                with gr.Accordion("Generation Parameters", open=False):
                    params_json = gr.JSON(label="Parameters Used")

                with gr.Accordion("Diffusion Process Details", open=False):
                    diffusion_json = gr.JSON(label="Process Metrics")

        # Set up the generation flow
        generate_btn.click(
            fn=generate_image,
            inputs=[prompt_input, negative_prompt, steps_slider, guidance_slider, seed_input],
            outputs=[output_image, generated_prompt, status_output, params_json, diffusion_json]
        )

        # Add examples
        gr.Examples(
            [
                ["Enchanted forest with a small creek", "people, humans, structures, buildings", 50, 7.5, 42],
                ["Ancient forest with giant trees", "snow, winter, dead trees", 40, 8.0, 123],
                ["Misty forest at dawn", "night, darkness, artificial lights", 60, 7.0, 456],
                ["", "", 40, 7.5, -1]  # Random generation
            ],
            [prompt_input, negative_prompt, steps_slider, guidance_slider, seed_input],
            fn=generate_image,
            outputs=[output_image, generated_prompt, status_output, params_json, diffusion_json],
        )


        with gr.Row():
            load_button = gr.Button("Load/Check Models")
            load_status = gr.Textbox(label="Model Status")

        load_button.click(
            fn=load_generation_models,
            inputs=[],
            outputs=[load_status]
        )

    return app


# Main Execution Block
if __name__ == "__main__":

    app = create_gradio_interface()
    app.launch(share=True, debug=True)

